{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil \n",
    "# 這兩個套件是為了要將訓練資料的路徑讀取工具也引進來\n",
    "\n",
    "import tensorflow as tf # 就是 Tensorflow 不用多說\n",
    "import tensorflow_hub as hub # Tensorflow bert 社群\n",
    "import tensorflow_text as text # 前處理\n",
    "from official.nlp import optimization  # 優化工具\n",
    "\n",
    "import matplotlib.pyplot as plt # 畫圖用的套件\n",
    "\n",
    "tf.get_logger().setLevel('ERROR') # Debug的工具，也可以不寫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 這個是資料集的下載連結，如果你複製這段 url 到瀏覽器上，也可以下載的到\n",
    "# url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "\n",
    "# dataset = tf.keras.utils.get_file('aclImdb_v1.tar.gz', url,\n",
    "#                                   untar=True, cache_dir='.',\n",
    "#                                   cache_subdir='')\n",
    "\n",
    "# # 所謂的 os.path.join 就是把兩個路徑結合起來的意思，如果路徑是 ./data/，join之後就會變成 ./data/aclImdb，而以下所做的，就是要整合資料路徑，方便之後模型讀取\n",
    "# dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
    "\n",
    "# train_dir = os.path.join(dataset_dir, 'train')\n",
    "\n",
    "# # remove unused folders to make it easier to load the data\n",
    "# remove_dir = os.path.join(train_dir, 'unsup')\n",
    "# shutil.rmtree(remove_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statement</th>\n",
       "      <th>isDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>After watching the new over-rated series Squid...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today on a math lesson the teacher told Vovoch...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A sequence of integers $$$b_1, b_2, \\ldots, b_...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Petya got interested in grammar on his third y...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nezzar designs a brand new game \"Hidden Permut...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7971</th>\n",
       "      <td>You are given an array of integers $$$a_1,a_2,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7972</th>\n",
       "      <td>Polycarp has a poor memory. Each day he can re...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7973</th>\n",
       "      <td>This is the hard version of the problem. The o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7974</th>\n",
       "      <td>Two chess pieces, a rook and a knight, stand o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7975</th>\n",
       "      <td>The first line contains a single integer $$$t$...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7976 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Statement   isDP\n",
       "0     After watching the new over-rated series Squid...  False\n",
       "1     Today on a math lesson the teacher told Vovoch...  False\n",
       "2     A sequence of integers $$$b_1, b_2, \\ldots, b_...   True\n",
       "3     Petya got interested in grammar on his third y...  False\n",
       "4     Nezzar designs a brand new game \"Hidden Permut...  False\n",
       "...                                                 ...    ...\n",
       "7971  You are given an array of integers $$$a_1,a_2,...   True\n",
       "7972  Polycarp has a poor memory. Each day he can re...  False\n",
       "7973  This is the hard version of the problem. The o...  False\n",
       "7974  Two chess pieces, a rook and a knight, stand o...  False\n",
       "7975  The first line contains a single integer $$$t$...  False\n",
       "\n",
       "[7976 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from core.general import *\n",
    "ls('../data')\n",
    "\n",
    "import pandas as pd\n",
    "f = pd.read_csv('../data/train_data.csv')\n",
    "f = f[['Statement', 'tags']]\n",
    "f['isDP'] = ['dp' in i for i in f['tags'].tolist()]\n",
    "f = f.drop('tags', axis = 1)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = f.to_dict()\n",
    "# for i in train:\n",
    "# debug(pwd())\n",
    "cd(root)\n",
    "cd('aclImdb/train')\n",
    "for tag in ['pos', True], ['neg', False]:\n",
    "    cd(tag[0])\n",
    "    for i in range(len(f['Statement'])):\n",
    "        if pre['isDP'][i] ^ tag[1]: continue;\n",
    "        write_to_file(f'{i}.txt', pre['Statement'][i])\n",
    "    cd('..')\n",
    "cd('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7976 files belonging to 2 classes.\n",
      "Using 6381 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 17:54:07.863620: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2025-01-13 17:54:07.863739: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-01-13 17:54:07.863846: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: ysh-laptop\n",
      "2025-01-13 17:54:07.863894: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: ysh-laptop\n",
      "2025-01-13 17:54:07.864075: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: NOT_FOUND: was unable to find libcuda.so DSO loaded into this program\n",
      "2025-01-13 17:54:07.864291: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 560.35.3\n",
      "2025-01-13 17:54:07.866572: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7976 files belonging to 2 classes.\n",
      "Using 1595 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "\n",
    "class_names = raw_train_ds.class_names\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=seed)\n",
    "\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/test',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: b\"This is an interactive problem.Khanh has $$$n$$$ points on the Cartesian plane, denoted by $$$a_1, a_2, \\\\ldots, a_n$$$. All points' coordinates are integers between $$$-10^9$$$ and $$$10^9$$$, inclusive. No three points are collinear. He says that these points are vertices of a convex polygon; in other words, there exists a permutation $$$p_1, p_2, \\\\ldots, p_n$$$ of integers from $$$1$$$ to $$$n$$$ such that the polygon $$$a_{p_1} a_{p_2} \\\\ldots a_{p_n}$$$ is convex and vertices are listed in counter-clockwise order.Khanh gives you the number $$$n$$$, but hides the coordinates of his points. Your task is to guess the above permutation by asking multiple queries. In each query, you give Khanh $$$4$$$ integers $$$t$$$, $$$i$$$, $$$j$$$, $$$k$$$; where either $$$t = 1$$$ or $$$t = 2$$$; and $$$i$$$, $$$j$$$, $$$k$$$ are three distinct indices from $$$1$$$ to $$$n$$$, inclusive. In response, Khanh tells you:  if $$$t = 1$$$, the area of the triangle $$$a_ia_ja_k$$$ multiplied by $$$2$$$.  if $$$t = 2$$$, the sign of the cross product of two vectors $$$\\\\overrightarrow{a_ia_j}$$$ and $$$\\\\overrightarrow{a_ia_k}$$$. Recall that the cross product of vector $$$\\\\overrightarrow{a} = (x_a, y_a)$$$ and vector $$$\\\\overrightarrow{b} = (x_b, y_b)$$$ is the integer $$$x_a \\\\cdot y_b - x_b \\\\cdot y_a$$$. The sign of a number is $$$1$$$ it it is positive, and $$$-1$$$ otherwise. It can be proven that the cross product obtained in the above queries can not be $$$0$$$.You can ask at most $$$3 \\\\cdot n$$$ queries.Please note that Khanh fixes the coordinates of his points and does not change it while answering your queries. You do not need to guess the coordinates. In your permutation $$$a_{p_1}a_{p_2}\\\\ldots a_{p_n}$$$, $$$p_1$$$ should be equal to $$$1$$$ and the indices of vertices should be listed in counter-clockwise order.\"\n",
      "Label : 0 (neg)\n",
      "Label : 0 (neg)\n",
      "Label : 0 (neg)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 17:54:09.962463: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "    print(f'Review: {text_batch.numpy()[0]}')\n",
    "    for i in range(3):\n",
    "        label = label_batch.numpy()[i]\n",
    "        print(f'Label : {label} ({class_names[label]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\" # 這是預訓練模型\n",
    "tfhub_handle_preprocess = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\" # 這是 BERT 前處理需要用的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[92mDEBUG\u001b[0m After watching the new over-rated series Squid Game, Mashtali and Soroush decided to hold their own Squid Games! Soroush agreed to be the host and will provide money for the winner's prize, and Mashtali became the Front Man!$$$m$$$ players registered to play in the games to win the great prize, but when Mashtali found out how huge the winner's prize is going to be, he decided to kill eliminate all the players so he could take the money for himself!Here is how evil Mashtali is going to eliminate players:There is an unrooted tree with $$$n$$$ vertices. Every player has $$$2$$$ special vertices $$$x_i$$$ and $$$y_i$$$.In one operation, Mashtali can choose any vertex $$$v$$$ of the tree. Then, for each remaining player $$$i$$$ he finds a vertex $$$w$$$ on the simple path from $$$x_i$$$ to $$$y_i$$$, which is the closest to $$$v$$$. If $$$w\\ne x_i$$$ and $$$w\\ne y_i$$$, player $$$i$$$ will be eliminated.Now Mashtali wondered: \"What is the minimum number of operations I should perform so that I can remove every player from the game and take the money for myself?\"Since he was only thinking about the money, he couldn't solve the problem by himself and asked for your help!\n"
     ]
    }
   ],
   "source": [
    "debug(pre['Statement'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_word_ids', 'input_mask', 'input_type_ids']\n",
      "Shape      : (1, 128)\n",
      "Word Ids   : [  101  2044  3666  1996  2047  2058  1011  6758  2186 26852  2208  1010]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess) # 呼叫前處理模型\n",
    "text_test = [pre['Statement'][0]] # 先輸入簡單的句子看看會變成什麼樣子\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[92mDEBUG\u001b[0m ---\n",
      "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Pooled Outputs Shape:(1, 512)\n",
      "Pooled Outputs Values:[ 0.8727445   0.917182   -0.26135486  0.17491198 -0.22153176 -0.8765021\n",
      "  0.99814    -0.97380465 -0.74489594 -0.9697282  -0.29953644 -0.9590922 ]\n",
      "Sequence Outputs Shape:(1, 128, 512)\n",
      "Sequence Outputs Values:[[-0.46256995  0.22983482 -0.15339413 ... -0.04324936  0.8477006\n",
      "  -0.06155542]\n",
      " [-0.8721482  -0.26003942 -0.4240116  ... -0.01380096 -0.506868\n",
      "   0.80026275]\n",
      " [-0.9195258   1.058085    1.0833865  ...  0.5954932   0.53631127\n",
      "   1.3289824 ]\n",
      " ...\n",
      " [-1.0381106  -0.08092016  0.25179073 ...  0.22761185  0.11991769\n",
      "  -0.3399005 ]\n",
      " [-1.3327754   0.16316739 -0.94576204 ... -0.04032091  0.2967144\n",
      "  -0.76678807]\n",
      " [-0.5673314  -0.11084812 -0.6279895  ... -0.30947086  0.49631402\n",
      "  -0.37789452]]\n"
     ]
    }
   ],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)\n",
    "debug('---')\n",
    "bert_results = bert_model(text_preprocessed)\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "  encoder_inputs = preprocessing_layer(text_input)\n",
    "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "  outputs = encoder(encoder_inputs)\n",
    "  net = outputs['pooled_output']\n",
    "  net = tf.keras.layers.Dropout(0.1)(net)\n",
    "  net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "  return tf.keras.Model(text_input, net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()\n",
    "\n",
    "epochs = 5\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = build_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 909s 4s/step - loss: 0.5494 - binary_accuracy: 0.7789 - val_loss: 0.5145 - val_binary_accuracy: 0.7868\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 842s 4s/step - loss: 0.5144 - binary_accuracy: 0.7847 - val_loss: 0.5143 - val_binary_accuracy: 0.7868\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 506s 3s/step - loss: 0.4791 - binary_accuracy: 0.7877 - val_loss: 0.5153 - val_binary_accuracy: 0.7868\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 272s 1s/step - loss: 0.4347 - binary_accuracy: 0.7945 - val_loss: 0.5245 - val_binary_accuracy: 0.7862\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 272s 1s/step - loss: 0.4038 - binary_accuracy: 0.8061 - val_loss: 0.5283 - val_binary_accuracy: 0.7843\n"
     ]
    }
   ],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)\n",
    "print(f'Training model with {tfhub_handle_encoder}')\n",
    "history = classifier_model.fit(x=train_ds,\n",
    "                               validation_data=val_ds,\n",
    "                               epochs=epochs)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 313s 400ms/step - loss: 1.1744 - binary_accuracy: 0.5000\n",
      "Loss: 1.1744247674942017\n",
      "Accuracy: 0.5000399947166443\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = classifier_model.evaluate(test_ds)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.save_weights('model.st')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
