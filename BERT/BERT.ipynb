{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 18:37:03.699780: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.6/lib64:\n",
      "2025-01-14 18:37:03.699827: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/ysh/miniconda3/envs/3.9/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/home/ysh/miniconda3/envs/3.9/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.4 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "# 這兩個套件是為了要將訓練資料的路徑讀取工具也引進來\n",
    "\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
    "\n",
    "import tensorflow as tf # 就是 Tensorflow 不用多說\n",
    "import tensorflow_hub as hub # Tensorflow bert 社群\n",
    "import tensorflow_text as text # 前處理\n",
    "from official.nlp import optimization  # 優化工具\n",
    "\n",
    "import matplotlib.pyplot as plt # 畫圖用的套件\n",
    "\n",
    "tf.get_logger().setLevel('ERROR') # Debug的工具，也可以不寫.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[96mINFO\u001b[0m  2.8.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 18:37:08.721891: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-14 18:37:08.916194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-01-14 18:37:08.920945: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.6/lib64:\n",
      "2025-01-14 18:37:08.921172: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.6/lib64:\n",
      "2025-01-14 18:37:08.921346: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.6/lib64:\n",
      "2025-01-14 18:37:08.921537: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.6/lib64:\n",
      "2025-01-14 18:37:09.039145: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.6/lib64:\n",
      "2025-01-14 18:37:09.039416: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-12.6/lib64:\n",
      "2025-01-14 18:37:09.039473: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from core.general import *\n",
    "\n",
    "info(tf.__version__)\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 這個是資料集的下載連結，如果你複製這段 url 到瀏覽器上，也可以下載的到\n",
    "# url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "\n",
    "# dataset = tf.keras.utils.get_file('aclImdb_v1.tar.gz', url,\n",
    "#                                   untar=True, cache_dir='.',\n",
    "#                                   cache_subdir='')\n",
    "\n",
    "# # 所謂的 os.path.join 就是把兩個路徑結合起來的意思，如果路徑是 ./data/，join之後就會變成 ./data/aclImdb，而以下所做的，就是要整合資料路徑，方便之後模型讀取\n",
    "# dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
    "\n",
    "# train_dir = os.path.join(dataset_dir, 'train')\n",
    "\n",
    "# # remove unused folders to make it easier to load the data\n",
    "# remove_dir = os.path.join(train_dir, 'unsup')\n",
    "# shutil.rmtree(remove_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statement</th>\n",
       "      <th>isDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>watch new seri squid game mashtali soroush dec...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>today math lesson teacher told vovochka euler ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sequenc integ call good max min sequenc integ ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>petya got interest grammar third year school i...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nezzar design brand new game hidden permut sha...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7971</th>\n",
       "      <td>given array integ find maximum possibl valu am...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7972</th>\n",
       "      <td>polycarp poor memori day rememb 3 differ lette...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7973</th>\n",
       "      <td>hard version problem differ easi version versi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7974</th>\n",
       "      <td>two chess piec rook knight stand standard ches...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7975</th>\n",
       "      <td>first line contain singl integ 1 32 number tes...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7976 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Statement   isDP\n",
       "0     watch new seri squid game mashtali soroush dec...  False\n",
       "1     today math lesson teacher told vovochka euler ...  False\n",
       "2     sequenc integ call good max min sequenc integ ...   True\n",
       "3     petya got interest grammar third year school i...  False\n",
       "4     nezzar design brand new game hidden permut sha...  False\n",
       "...                                                 ...    ...\n",
       "7971  given array integ find maximum possibl valu am...   True\n",
       "7972  polycarp poor memori day rememb 3 differ lette...  False\n",
       "7973  hard version problem differ easi version versi...  False\n",
       "7974  two chess piec rook knight stand standard ches...  False\n",
       "7975  first line contain singl integ 1 32 number tes...  False\n",
       "\n",
       "[7976 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from core.general import *\n",
    "ls('../data')\n",
    "\n",
    "import pandas as pd\n",
    "f = pd.read_csv('../data/filtered_train_data.csv')\n",
    "f = f[['Statement', 'tags']]\n",
    "f['isDP'] = ['dp' in i for i in f['tags'].tolist()]\n",
    "f = f.drop('tags', axis = 1)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = f.to_dict()\n",
    "# for i in train:\n",
    "# debug(pwd())\n",
    "cd(root)\n",
    "cd('aclImdb/train')\n",
    "for tag in ['pos', True], ['neg', False]:\n",
    "    cd(tag[0])\n",
    "    for i in range(len(f['Statement'])):\n",
    "        if pre['isDP'][i] ^ tag[1]: continue;\n",
    "        write_to_file(f'{i}.txt', pre['Statement'][i])\n",
    "    cd('..')\n",
    "cd('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[96mINFO\u001b[0m  Loading Training Data.\n",
      "Found 7976 files belonging to 2 classes.\n",
      "Using 6381 files for training.\n",
      "\u001b[1m\u001b[96mINFO\u001b[0m  Loading Validating Data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 18:37:10.508175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-01-14 18:37:10.509649: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7976 files belonging to 2 classes.\n",
      "Using 1595 files for validation.\n",
      "\u001b[1m\u001b[96mINFO\u001b[0m  Loading Testing Data.\n",
      "Found 1995 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "info('Loading Training Data.')\n",
    "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "\n",
    "class_names = raw_train_ds.class_names\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "info('Loading Validating Data.')\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=seed)\n",
    "\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "info('Loading Testing Data.')\n",
    "test_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/test',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: b'interact n point cartesian plane denot point coordin integ inclus three point collinear say point vertic convex polygon word exist permut integ 1 n polygon convex vertic list give number n hide coordin point task guess permut ask multipl queri queri give khanh 4 integ j k either 1 2 j k three distinct indic 1 n inclus respons khanh tell 1 area triangl multipli 2 2 sign cross product two vector recal cross product vector vector b integ sign number 1 posit otherwis proven cross product obtain queri 0 ask 3 n note khanh fix coordin point chang answer queri need guess coordin permut equal 1 indic vertic list order'\n",
      "Label : 0 (neg)\n",
      "Label : 0 (neg)\n",
      "Label : 0 (neg)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 18:37:11.029202: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "    print(f'Review: {text_batch.numpy()[0]}')\n",
    "    for i in range(3):\n",
    "        label = label_batch.numpy()[i]\n",
    "        print(f'Label : {label} ({class_names[label]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\" # 這是預訓練模型\n",
    "tfhub_handle_preprocess = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\" # 這是 BERT 前處理需要用的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[92mDEBUG\u001b[0m watch new seri squid game mashtali soroush decid hold squid game soroush agre host provid money winner prize mashtali becam front man player regist play game win great prize mashtali found huge winner prize go decid kill elimin player could take money evil mashtali go elimin player unroot tree n vertic everi player 2 special vertic one oper mashtali choos vertex v tree remain player find vertex w simpl path closest v player mashtali wonder minimum number oper perform remov everi player game take money sinc think money could solv problem ask help\n"
     ]
    }
   ],
   "source": [
    "debug(pre['Statement'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_word_ids', 'input_mask', 'input_type_ids']\n",
      "Shape      : (1, 128)\n",
      "Word Ids   : [  101  3422  2047 14262  2072 26852  2208 16137 22893  3669  2061 13288]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess) # 呼叫前處理模型\n",
    "text_test = [pre['Statement'][0]] # 先輸入簡單的句子看看會變成什麼樣子\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[92mDEBUG\u001b[0m ---\n",
      "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Pooled Outputs Shape:(1, 512)\n",
      "Pooled Outputs Values:[ 0.99807113  0.7797979  -0.0370684   0.3995302   0.07245599  0.40720418\n",
      "  0.9682053  -0.99730515 -0.7465364  -0.88527596 -0.4546446   0.83189595]\n",
      "Sequence Outputs Shape:(1, 128, 512)\n",
      "Sequence Outputs Values:[[-9.28442657e-01  1.04626226e+00 -5.84454834e-01 ... -7.04503477e-01\n",
      "  -2.72823095e-01 -4.49318707e-01]\n",
      " [-2.51816779e-01  4.96864468e-02  6.76903844e-01 ... -2.99022317e-01\n",
      "  -6.40931189e-01  1.29349545e-01]\n",
      " [-5.00569940e-01 -1.29153579e-03 -7.94892311e-01 ... -1.20398566e-01\n",
      "  -3.05489123e-01  2.88654476e-01]\n",
      " ...\n",
      " [-1.28959584e+00  5.35864770e-01 -3.78003418e-02 ...  1.31041276e+00\n",
      "   7.49447703e-01  1.61270738e-01]\n",
      " [-7.77777791e-01 -9.57850695e-01 -1.97193012e-01 ... -5.76900840e-01\n",
      "   3.61313820e-01  6.66653514e-01]\n",
      " [-5.03935218e-01  1.62717581e-01 -1.52471632e-01 ...  1.60439789e-01\n",
      "  -7.64720619e-01 -6.24636829e-01]]\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    bert_model = hub.KerasLayer(tfhub_handle_encoder)\n",
    "    debug('---')\n",
    "    bert_results = bert_model(text_preprocessed)\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "  encoder_inputs = preprocessing_layer(text_input)\n",
    "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "  outputs = encoder(encoder_inputs)\n",
    "  net = outputs['pooled_output']\n",
    "  net = tf.keras.layers.Dropout(0.1)(net)\n",
    "  net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "  return tf.keras.Model(text_input, net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()\n",
    "\n",
    "epochs = 3\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = build_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 738s 4s/step - loss: 0.5473 - binary_accuracy: 0.7837 - val_loss: 0.5488 - val_binary_accuracy: 0.7868\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 675s 3s/step - loss: 0.5074 - binary_accuracy: 0.7880 - val_loss: 0.5055 - val_binary_accuracy: 0.7868\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 671s 3s/step - loss: 0.4603 - binary_accuracy: 0.7989 - val_loss: 0.5246 - val_binary_accuracy: 0.7837\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 672s 3s/step - loss: 0.4245 - binary_accuracy: 0.8134 - val_loss: 0.5510 - val_binary_accuracy: 0.7781\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 671s 3s/step - loss: 0.3781 - binary_accuracy: 0.8348 - val_loss: 0.6081 - val_binary_accuracy: 0.7875\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 650s 3s/step - loss: 0.3348 - binary_accuracy: 0.8516 - val_loss: 0.6577 - val_binary_accuracy: 0.7912\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 281s 1s/step - loss: 0.2912 - binary_accuracy: 0.8710 - val_loss: 0.6727 - val_binary_accuracy: 0.7818\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 291s 1s/step - loss: 0.2539 - binary_accuracy: 0.8927 - val_loss: 0.7263 - val_binary_accuracy: 0.7724\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 309s 2s/step - loss: 0.2237 - binary_accuracy: 0.9060 - val_loss: 0.7392 - val_binary_accuracy: 0.7643\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 267s 1s/step - loss: 0.2035 - binary_accuracy: 0.9174 - val_loss: 0.7584 - val_binary_accuracy: 0.7618\n"
     ]
    }
   ],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)\n",
    "print(f'Training model with {tfhub_handle_encoder}')\n",
    "history = classifier_model.fit(x=train_ds,\n",
    "                               validation_data=val_ds,\n",
    "                               epochs=epochs)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 23s 365ms/step - loss: 0.7817 - binary_accuracy: 0.7539\n",
      "Loss: 0.7816520929336548\n",
      "Accuracy: 0.7538847327232361\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = classifier_model.evaluate(test_ds)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.save_weights('model.st')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[92mDEBUG\u001b[0m 1713\n",
      "\u001b[1m\u001b[92mDEBUG\u001b[0m 7976\n"
     ]
    }
   ],
   "source": [
    "debug([pre['isDP'][i] for i in list(pre['isDP'])].count(True))\n",
    "debug(len(pre['isDP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statement</th>\n",
       "      <th>isDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hard version problem differ version k 12 make ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>problem differ next one presenc constraint equ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>array b call subarray form continu subsequ equ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>athenaeu finish creat latest music composit pr...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>got posit integ sequenc a1 a2 number sequenc d...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>100 room arrang row 99 door door connect room ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>littl artyom decid studi probabl theori found ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>given sequenc a1 a2 queri lj rj 1 lj rj n quer...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>grid n row column three type cell empti cell d...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>land fire n villag bidirect road path pair vil...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1995 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Statement   isDP\n",
       "0     hard version problem differ version k 12 make ...  False\n",
       "1     problem differ next one presenc constraint equ...  False\n",
       "2     array b call subarray form continu subsequ equ...  False\n",
       "3     athenaeu finish creat latest music composit pr...   True\n",
       "4     got posit integ sequenc a1 a2 number sequenc d...   True\n",
       "...                                                 ...    ...\n",
       "1990  100 room arrang row 99 door door connect room ...  False\n",
       "1991  littl artyom decid studi probabl theori found ...   True\n",
       "1992  given sequenc a1 a2 queri lj rj 1 lj rj n quer...  False\n",
       "1993  grid n row column three type cell empti cell d...  False\n",
       "1994  land fire n villag bidirect road path pair vil...  False\n",
       "\n",
       "[1995 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/filtered_test_data.csv')\n",
    "df = df[['Statement', 'tags']]\n",
    "df['isDP'] = ['dp' in i for i in df['tags'].tolist()]\n",
    "df = df.drop('tags', axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[96mINFO\u001b[0m  [OK] Task Parse neg Finished.\n",
      "\u001b[1m\u001b[96mINFO\u001b[0m  [OK] Task Parse pos Finished.\n"
     ]
    }
   ],
   "source": [
    "now = df.to_dict()\n",
    "n = len(now['Statement'])\n",
    "cd(root)\n",
    "cd('aclImdb')\n",
    "cd ('test')\n",
    "for tag in ['neg', 0], ['pos', 1]:\n",
    "    cd(tag[0])\n",
    "    for i in range(n):\n",
    "        if now['isDP'][i] ^ tag[1]: continue;\n",
    "        info(f'[{i} / {n}] Parsing Rows', end = '\\r')\n",
    "        write_to_file(f'{i}.txt', now['Statement'][i])\n",
    "    info(f'[OK] Task Parse {tag[0]} Finished.')\n",
    "    cd('..')\n",
    "cd('../..')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
